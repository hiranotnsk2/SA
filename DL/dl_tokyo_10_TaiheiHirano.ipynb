{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from sklearn.model_selection import train_test_split # ホールドアウト法に関する関数\n",
    "#import matplotlib.pyplot as plt\n",
    "#from collections import OrderedDict\n",
    "#from common.layers import Convolution, MaxPooling, ReLU, Affine, Dropout, SoftmaxWithLoss\n",
    "#from common.optimizer import RMSProp, SGD, Adam\n",
    "#from common.nn import SimpleConvNet\n",
    "#from common.deep_convnet import DeepConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59951, 1, 28, 28)\n",
      "(59951, 15)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load(\"./train_data_mr.npy\")\n",
    "train_label = np.load(\"./train_label_mr.npy\")\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2        # 全データのうち、何%をテストデータにするか（今回は20%に設定）\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_label, test_size=test_size, random_state=1234) # ホールドアウト法を実行（テストデータはランダム選択）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正規化\n",
    "X_train = (X_train - X_train.min()) / (X_train.max() - X_train.min())\n",
    "X_train = X_train.astype('float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train\n",
    "t = y_train\n",
    "\n",
    "#x = x.reshape(-1,1,28,28) # 配列形式の変換\n",
    "x = x.transpose(0, 2, 3, 1)\n",
    "X_test = X_test.transpose(0, 2, 3, 1)\n",
    "\n",
    "#epochs = 200\n",
    "#batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train1, x_valid, y_train1, y_valid = train_test_split(x_train, y_train, test_size=0.175)\n",
    "x_train = x_train1\n",
    "y_train = y_train1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')/255\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], 28, 28, 1).astype('float32')/255\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')/255\n",
    "\n",
    "# convert one-hot vector\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_valid = keras.utils.to_categorical(y_valid, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\officemino\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\officemino\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\officemino\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\officemino\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\officemino\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\officemino\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\officemino\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\officemino\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                1935      \n",
      "=================================================================\n",
      "Total params: 1,200,527\n",
      "Trainable params: 1,200,527\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\officemino\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 47960 samples, validate on 11991 samples\n",
      "Epoch 1/56\n",
      "47960/47960 [==============================] - 37s 764us/step - loss: 0.6597 - acc: 0.7981 - val_loss: 0.7660 - val_acc: 0.9515\n",
      "Epoch 2/56\n",
      "47960/47960 [==============================] - 37s 764us/step - loss: 0.2290 - acc: 0.9275 - val_loss: 0.6092 - val_acc: 0.9617\n",
      "Epoch 3/56\n",
      "47960/47960 [==============================] - 37s 771us/step - loss: 0.1612 - acc: 0.9490 - val_loss: 0.4510 - val_acc: 0.9716\n",
      "Epoch 4/56\n",
      "47960/47960 [==============================] - 37s 772us/step - loss: 0.1269 - acc: 0.9561 - val_loss: 0.4741 - val_acc: 0.9701\n",
      "Epoch 5/56\n",
      "47960/47960 [==============================] - 37s 780us/step - loss: 0.1084 - acc: 0.9632 - val_loss: 0.4472 - val_acc: 0.9718\n",
      "Epoch 6/56\n",
      "47960/47960 [==============================] - 38s 782us/step - loss: 0.0904 - acc: 0.9698 - val_loss: 0.4021 - val_acc: 0.9749\n",
      "Epoch 7/56\n",
      "47960/47960 [==============================] - 37s 779us/step - loss: 0.0806 - acc: 0.9729 - val_loss: 0.3434 - val_acc: 0.9782\n",
      "Epoch 8/56\n",
      "47960/47960 [==============================] - 37s 781us/step - loss: 0.0714 - acc: 0.9751 - val_loss: 0.3443 - val_acc: 0.9782\n",
      "Epoch 9/56\n",
      "47960/47960 [==============================] - 38s 783us/step - loss: 0.0621 - acc: 0.9794 - val_loss: 0.2477 - val_acc: 0.9843\n",
      "Epoch 10/56\n",
      "47960/47960 [==============================] - 38s 784us/step - loss: 0.0600 - acc: 0.9791 - val_loss: 0.2226 - val_acc: 0.9860\n",
      "Epoch 11/56\n",
      "47960/47960 [==============================] - 38s 788us/step - loss: 0.0575 - acc: 0.9803 - val_loss: 0.2111 - val_acc: 0.9869\n",
      "Epoch 12/56\n",
      "47960/47960 [==============================] - 38s 784us/step - loss: 0.0487 - acc: 0.9839 - val_loss: 0.3009 - val_acc: 0.9812\n",
      "Epoch 13/56\n",
      "47960/47960 [==============================] - 38s 793us/step - loss: 0.0487 - acc: 0.9830 - val_loss: 0.3166 - val_acc: 0.9802\n",
      "Epoch 14/56\n",
      "47960/47960 [==============================] - 38s 787us/step - loss: 0.0403 - acc: 0.9864 - val_loss: 0.2730 - val_acc: 0.9829\n",
      "Epoch 15/56\n",
      "47960/47960 [==============================] - 38s 783us/step - loss: 0.0408 - acc: 0.9864 - val_loss: 0.1733 - val_acc: 0.9892\n",
      "Epoch 16/56\n",
      "47960/47960 [==============================] - 38s 791us/step - loss: 0.0377 - acc: 0.9867 - val_loss: 0.2441 - val_acc: 0.9847\n",
      "Epoch 17/56\n",
      "47960/47960 [==============================] - 38s 788us/step - loss: 0.0389 - acc: 0.9861 - val_loss: 0.1529 - val_acc: 0.9904\n",
      "Epoch 18/56\n",
      "47960/47960 [==============================] - 37s 776us/step - loss: 0.0320 - acc: 0.9888 - val_loss: 0.2050 - val_acc: 0.9870\n",
      "Epoch 19/56\n",
      "47960/47960 [==============================] - 38s 785us/step - loss: 0.0319 - acc: 0.9892 - val_loss: 0.1168 - val_acc: 0.9927\n",
      "Epoch 20/56\n",
      "47960/47960 [==============================] - 37s 782us/step - loss: 0.0289 - acc: 0.9898 - val_loss: 0.1039 - val_acc: 0.9935\n",
      "Epoch 21/56\n",
      "47960/47960 [==============================] - 38s 782us/step - loss: 0.0271 - acc: 0.9904 - val_loss: 0.1132 - val_acc: 0.9928\n",
      "Epoch 22/56\n",
      "47960/47960 [==============================] - 38s 784us/step - loss: 0.0297 - acc: 0.9899 - val_loss: 0.0954 - val_acc: 0.9941\n",
      "Epoch 23/56\n",
      "47960/47960 [==============================] - 37s 780us/step - loss: 0.0281 - acc: 0.9902 - val_loss: 0.1475 - val_acc: 0.9907\n",
      "Epoch 24/56\n",
      "47960/47960 [==============================] - 38s 785us/step - loss: 0.0262 - acc: 0.9912 - val_loss: 0.0901 - val_acc: 0.9944\n",
      "Epoch 25/56\n",
      "47960/47960 [==============================] - 38s 782us/step - loss: 0.0238 - acc: 0.9920 - val_loss: 0.1249 - val_acc: 0.9922\n",
      "Epoch 26/56\n",
      "47960/47960 [==============================] - 38s 796us/step - loss: 0.0274 - acc: 0.9905 - val_loss: 0.0885 - val_acc: 0.9944\n",
      "Epoch 27/56\n",
      "47960/47960 [==============================] - 38s 796us/step - loss: 0.0213 - acc: 0.9926 - val_loss: 0.0888 - val_acc: 0.9944\n",
      "Epoch 28/56\n",
      "47960/47960 [==============================] - 38s 787us/step - loss: 0.0234 - acc: 0.9919 - val_loss: 0.1080 - val_acc: 0.9932\n",
      "Epoch 29/56\n",
      "47960/47960 [==============================] - 38s 786us/step - loss: 0.0183 - acc: 0.9940 - val_loss: 0.1169 - val_acc: 0.9927\n",
      "Epoch 30/56\n",
      "47960/47960 [==============================] - 38s 793us/step - loss: 0.0205 - acc: 0.9931 - val_loss: 0.0837 - val_acc: 0.9947\n",
      "Epoch 31/56\n",
      "47960/47960 [==============================] - 38s 784us/step - loss: 0.0192 - acc: 0.9931 - val_loss: 0.1067 - val_acc: 0.9933\n",
      "Epoch 32/56\n",
      "47960/47960 [==============================] - 38s 795us/step - loss: 0.0194 - acc: 0.9935 - val_loss: 0.0912 - val_acc: 0.9942\n",
      "Epoch 33/56\n",
      "47960/47960 [==============================] - 38s 788us/step - loss: 0.0204 - acc: 0.9927 - val_loss: 0.0941 - val_acc: 0.9942\n",
      "Epoch 34/56\n",
      "47960/47960 [==============================] - 38s 793us/step - loss: 0.0182 - acc: 0.9936 - val_loss: 0.0752 - val_acc: 0.9953\n",
      "Epoch 35/56\n",
      "24100/47960 [==============>...............] - ETA: 17s - loss: 0.0158 - acc: 0.9942"
     ]
    }
   ],
   "source": [
    "# callback function\n",
    "#plot_losses = PlotLosses()      # グラフ表示(live plot)\n",
    "#plot_losses.epochs = epochs\n",
    "#csv_logger = CSVLogger('trainlog.csv')\n",
    "\n",
    "# train\n",
    "history = model.fit(x, t,\n",
    "                    batch_size=100, epochs=56,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "# result\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss: {0}'.format(score[0]))\n",
    "print('Test accuracy: {0}'.format(score[1]))\n",
    "\n",
    "plot_result(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
